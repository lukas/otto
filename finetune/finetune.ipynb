{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b17b3b4d-54ea-47d7-ab14-42e7b42914de",
   "metadata": {},
   "source": [
    "# Finetune an OSS model for out bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed8576-edd5-400b-b563-b3c16b4e3617",
   "metadata": {},
   "source": [
    "We will use the [trl]() library to make our life easy! Most of the code comes from the official [trl finetune example](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0fd751-8abf-4313-9158-26bb68751160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install accelerate transformers datasets bitsandbytes peft trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9961a849-6c5e-4d3f-8f87-d46406a492ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, HfArgumentParser, TrainingArguments\n",
    "\n",
    "import wandb\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from ft_utils import read_file, load_ds_from_artifact, LLMSampleCB, generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc019a42-86d6-4f33-bec7-af7f73c238d9",
   "metadata": {},
   "source": [
    "What is really handy here is the data preprocessing that is baked into the `SFTTrainer` class, this trainer is a thing wrapper around the transformer's `Trainer` but adds the necessary preprocessing needed to format and pack our instruction dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ab8be-1460-4aaf-891a-99f1d92d5a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd96c4-320e-463d-a664-d3b512598e72",
   "metadata": {},
   "source": [
    "We will grab our dataset previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f0f25b6-c42a-43a5-b50e-d6f983ac6d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data_path = \"dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f6a21fd-2678-4a64-93a2-504b23d7da8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# by default the split is called train\n",
    "ds = load_dataset(\"json\", data_files=f\"{training_data_path}/*.json\")[\"train\"].shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c77dcc18-c244-421a-a3e7-5e5974ffef5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user', 'answer'],\n",
       "    num_rows: 616\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2563f6ea-f76b-4b72-b9e1-e409e8994e07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': [\"Bats are just regular old flying mammals. But don't tell anyone I said that, or they might start\",\n",
       "  'You know, Goldilocks and the Three Bears?',\n",
       "  'Thanks.'],\n",
       " 'answer': ['other()', 'other()', 'other()']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7741ef5b-f1c8-475e-95b8-7cd2676ad513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splitted_ds = ds.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a32cb-32af-4b76-a2fb-ddcba8603178",
   "metadata": {},
   "source": [
    "Let's save this split in Hugging Face dataset format (fast parquet files unde the hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd0eb455-145b-4e99-bb63-3fc07de87216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508fe34623db4c54b008ab2488380583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/554 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63bda5a0276466dae78a11e1f0d1e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splitted_ds.save_to_disk(f\"{training_data_path}/split_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b74605-e102-4408-a450-9cc2d373531d",
   "metadata": {},
   "source": [
    "Let's save this to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5378d73a-4b2b-4e54-b371-7bc50cc218b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # You only need to do this once\n",
    "# with wandb.init(project=\"otto\", job_type=\"data_split\"):\n",
    "#     at = wandb.Artifact(name=\"split_dataset\",\n",
    "#                         type=\"dataset\",\n",
    "#                         description=\"The generated data splitted in 90/10\")\n",
    "#     at.add_dir(f\"{training_data_path}/split_dataset\")\n",
    "#     wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59f0e351-95fe-45e1-b53c-d1ff4fb3aabc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_ARTIFACT = 'capecape/otto/split_dataset:v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecdff480-ab3d-40a1-9900-5ebc84c6ba76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   7 of 7 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['user', 'answer'],\n",
       "        num_rows: 554\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['user', 'answer'],\n",
       "        num_rows: 62\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_ds_from_artifact(DATASET_ARTIFACT)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e7461-3296-43ba-b6ef-35b1ec480ac0",
   "metadata": {},
   "source": [
    "## Prepare data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a232f-a2f6-4f0c-9269-f128b3c2fba6",
   "metadata": {},
   "source": [
    "> Depending on the model you will need to change this formatting function\n",
    "\n",
    "We will train a Llama2 model from MetaAI, depending if it is the `chat` or `vanilla` version, you will need to format your instructions differently. My to go place to find these format is the hugginface model card (but many times it is missing), the official paper (can be hard to find) or the [Axolotl training library](https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/src/axolotl/prompt_strategies/llama2_chat.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8528f94-122b-4dc7-bbf0-4b1dc11c23d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mistral_prompt = \"\"\"[INST]You are AI that converts human request into api calls. \n",
    "You have a set of functions:\n",
    "-news(topic=\"[topic]\") asks for latest headlines about a topic.\n",
    "-math(question=\"[question]\") asks a math question in python format.\n",
    "-notes(action=\"add|list\", note=\"[note]\") lets a user take simple notes.\n",
    "-openai(prompt=\"[prompt]\") asks openai a question.\n",
    "-runapp(program=\"[program]\") runs a program locally.\n",
    "-story(description=[description]) lets a user ask for a story.\n",
    "-timecheck(location=\"[location]\") ask for the time at a location. If no location is given it's assumed to be the current location.\n",
    "-timer(duration=\"[duration]\") sets a timer for duration written out as a string.\n",
    "-weather(location=\"[location]\") ask for the weather at a location. If there's no location string the location is assumed to be where the user is.\n",
    "-other() should be used when none of the other commands apply\n",
    "\n",
    "Here is a user request, reply with the corresponding function call, be brief.\n",
    "USER_QUERY: {user}[/INST]{answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64e9b126-ad58-4f45-8afd-4a071ef75826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _create_mistral_instruct_prompt(user, answer=\"\"):\n",
    "    return mistral_prompt.format(user=user, answer=answer)\n",
    "\n",
    "def create_prompt(row): return _create_mistral_instruct_prompt(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89db80a1-94f0-4935-a5ea-e9d04a31d87d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]You are AI that converts human request into api calls. \n",
      "You have a set of functions:\n",
      "-news(topic=\"[topic]\") asks for latest headlines about a topic.\n",
      "-math(question=\"[question]\") asks a math question in python format.\n",
      "-notes(action=\"add|list\", note=\"[note]\") lets a user take simple notes.\n",
      "-openai(prompt=\"[prompt]\") asks openai a question.\n",
      "-runapp(program=\"[program]\") runs a program locally.\n",
      "-story(description=[description]) lets a user ask for a story.\n",
      "-timecheck(location=\"[location]\") ask for the time at a location. If no location is given it's assumed to be the current location.\n",
      "-timer(duration=\"[duration]\") sets a timer for duration written out as a string.\n",
      "-weather(location=\"[location]\") ask for the weather at a location. If there's no location string the location is assumed to be where the user is.\n",
      "-other() should be used when none of the other commands apply\n",
      "\n",
      "Here is a user request, reply with the corresponding function call, be brief.\n",
      "USER_QUERY: I'll get this flowy.[/INST]other()\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(ds[\"train\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38a83c10-f88a-4085-a124-3a8c7c5c99d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# Define and parse arguments.\n",
    "script_args=SimpleNamespace(\n",
    "    model_name=MODEL_NAME,               # \"the model name\"\n",
    "    dataset_artifact=DATASET_ARTIFACT,   # \"the W&B artifact holding the dataset\n",
    "    log_with=\"wandb\",                    # \"use 'wandb' to log with wandb\"\n",
    "    learning_rate=1.4e-5,                # \"the learning rate\"\n",
    "    batch_size=2,                        # \"the batch size\", 24GB -> 2, 40GB -> 4\n",
    "    seq_length=400,                      # \"Input sequence length\"\n",
    "    gradient_accumulation_steps=16,      # \"simulate larger batch sizes\"\n",
    "    load_in_x_bits=4,                    # \"load the model in 4/8 precision\n",
    "    use_peft=True,                       # \"Wether to use PEFT or not to train adapters\"\n",
    "    output_dir=\"output\",                 # \"the output directory\"\n",
    "    peft_lora_r=64,                      # \"the rank of the matrix parameter of the LoRA adapters\"\n",
    "    peft_lora_alpha=16,                  # \"the alpha parameter of the LoRA adapters\"\n",
    "    logging_steps=1,                     # \"How often to log\"\n",
    "    use_auth_token=True,                 # \"Use HF auth token to access the model\"\n",
    "    max_steps=500,                       # \"the number of training steps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015974c7-a1ff-4687-ac33-0a626067f96e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7612a-87f1-4e94-9e8d-9cf0979613e2",
   "metadata": {},
   "source": [
    "We can load the model with all the bells and whistles from Transformers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62b6c7e8-e5ee-4cdf-9534-87ca90a6e5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a16616865f44de79852450cdcaf1885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Load the model\n",
    "if script_args.load_in_x_bits in [4,8]:\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=script_args.load_in_x_bits==8, \n",
    "        load_in_4bit=script_args.load_in_x_bits==4\n",
    "    )\n",
    "else:\n",
    "    quantization_config = None\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    script_args.model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_auth_token=script_args.use_auth_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d507a281-98c4-4454-8ce0-ed54066deddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=script_args.output_dir,\n",
    "    per_device_train_batch_size=script_args.batch_size,\n",
    "    per_device_eval_batch_size=script_args.batch_size,\n",
    "    gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n",
    "    learning_rate=script_args.learning_rate,\n",
    "    logging_steps=script_args.logging_steps,\n",
    "    # num_train_epochs=script_args.num_train_epochs,\n",
    "    max_steps=script_args.max_steps,\n",
    "    report_to=script_args.log_with,\n",
    ")\n",
    "\n",
    "\n",
    "# Step 4: Define the LoraConfig\n",
    "if script_args.use_peft:\n",
    "    peft_config = LoraConfig(\n",
    "        r=script_args.peft_lora_r,\n",
    "        lora_alpha=script_args.peft_lora_alpha,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    )\n",
    "else:\n",
    "    peft_config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dfec5c-3c8b-42f2-8cc7-28f33c13d39d",
   "metadata": {},
   "source": [
    "Now we need to instantiate the `SFTTrainer` with the correct preprocessing:\n",
    "- We want to pack sequences to a certain length (longer means more memory usage)\n",
    "- We want to tokenize\n",
    "- We also want to apply our prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67c08d2c-0830-4510-b32c-ed99e3844b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_args.seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e91cec6-c81d-4331-855c-23f873487268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args.eval_steps = training_args.max_steps // 5\n",
    "training_args.evaluation_strategy = \"steps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e46da0fc-8af8-4730-b218-6db315b75710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/cape/otto/finetune/wandb/run-20231101_123933-0d25ji1b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/otto/runs/0d25ji1b' target=\"_blank\">ethereal-microwave-128</a></strong> to <a href='https://wandb.ai/capecape/otto' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/otto' target=\"_blank\">https://wandb.ai/capecape/otto</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/otto/runs/0d25ji1b' target=\"_blank\">https://wandb.ai/capecape/otto/runs/0d25ji1b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   7 of 7 files downloaded.  \n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"otto\", job_type=\"finetune\")\n",
    "    \n",
    "ds = load_ds_from_artifact(DATASET_ARTIFACT)\n",
    "    \n",
    "# Step 5: Define the Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    args=training_args,\n",
    "    max_seq_length=script_args.seq_length,\n",
    "    packing=True,\n",
    "    formatting_func=create_prompt,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd2e28-2059-4bf5-bdfa-d162d6a35978",
   "metadata": {},
   "source": [
    "to be sure, let's check the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab1daacc-5a73-40a3-9ec8-cfd7c0f852b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.\\n-weather(location=\"[location]\") ask for the weather at a location. If there\\'s no location string the location is assumed to be where the user is.\\n-other() should be used when none of the other commands apply\\n\\nHere is a user request, reply with the corresponding function call, be brief.\\nUSER_QUERY: Turn the brake![/INST]other()</s><s> [INST]You are AI that converts human request into api calls. \\nYou have a set of functions:\\n-news(topic=\"[topic]\") asks for latest headlines about a topic.\\n-math(question=\"[question]\") asks a math question in python format.\\n-notes(action=\"add|list\", note=\"[note]\") lets a user take simple notes.\\n-openai(prompt=\"[prompt]\") asks openai a question.\\n-runapp(program=\"[program]\") runs a program locally.\\n-story(description=[description]) lets a user ask for a story.\\n-timecheck(location=\"[location]\") ask for the time at a location. If no location is given it\\'s assumed to be the current location.\\n-timer(duration=\"[duration]\") sets a timer for duration written out as a string.\\n-weather(location=\"[location]\") ask for the weather at a location. If there\\'s no location string the location is assumed to be where the user is.\\n-other() should be used when none of the other commands apply\\n\\nHere is a user request, reply with the corresponding function call, be brief.\\nUSER_QUERY: Inquire if elephants can dance[/INST]openai(prompt=\"Can elephants dance?\")</s><s> [INST]You are AI that converts human request into api calls. \\nYou have a'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = trainer.get_train_dataloader()\n",
    "b = next(iter(dl))\n",
    "trainer.tokenizer.decode(b[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75110232-61f2-4bc5-88d1-cdbc549ad127",
   "metadata": {},
   "source": [
    "Let's sample from the model during Training, to do this we will add a custom WandbCallback that has access to the Trainer object (and model and tokenizer). Normally, callback don't have access to these, and that's why we need to add it to the instantiated Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "674b1b0a-e2c9-4314-853a-9f23d0a25767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad954bc64d594c71bd10bb51592553f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_test_prompt = lambda row: {\"text\": create_prompt({\"user\": row[\"user\"], \"answer\": \"\"})}  # remove output\n",
    "\n",
    "test_dataset = ds[\"test\"].map(create_test_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "847757b8-018a-48c3-b959-e087933e7769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[INST]You are AI that converts human request into api calls. \\nYou have a set of functions:\\n-news(topic=\"[topic]\") asks for latest headlines about a topic.\\n-math(question=\"[question]\") asks a math question in python format.\\n-notes(action=\"add|list\", note=\"[note]\") lets a user take simple notes.\\n-openai(prompt=\"[prompt]\") asks openai a question.\\n-runapp(program=\"[program]\") runs a program locally.\\n-story(description=[description]) lets a user ask for a story.\\n-timecheck(location=\"[location]\") ask for the time at a location. If no location is given it\\'s assumed to be the current location.\\n-timer(duration=\"[duration]\") sets a timer for duration written out as a string.\\n-weather(location=\"[location]\") ask for the weather at a location. If there\\'s no location string the location is assumed to be where the user is.\\n-other() should be used when none of the other commands apply\\n\\nHere is a user request, reply with the corresponding function call, be brief.\\nUSER_QUERY: Cheers![/INST]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = test_dataset[0][\"text\"]\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feebc470-9492-470e-83e1-8c1a3094f130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "gen_config = GenerationConfig.from_pretrained(script_args.model_name, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb27c6c5-cd10-4f54-9fde-9713a6ada9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FUNCTION_CALL: other()'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(prompt, trainer.model, trainer.tokenizer, gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a149e-fa5d-4da7-8948-166eab833f14",
   "metadata": {},
   "source": [
    "this a already pretty good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13672553-1a7b-4408-a661-baa5b44092b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's finetune to force it reply with the function call only!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d41ab-cce3-4670-9f6e-2bf8623ac7cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "we add the LLMSampleCB to log examples during training. Let's pick the examples first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "022f0540-bf0f-4cfd-99d5-3003b1f8a791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "hand_picked_ds = Dataset.from_list([test_dataset[0],])\n",
    "for s in test_dataset:\n",
    "    if s[\"answer\"] not in [t[\"answer\"] for t in hand_picked_ds]:\n",
    "        hand_picked_ds = hand_picked_ds.add_item(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d84675c1-2a8f-4c65-a66b-fdbf4607e120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb_cb = LLMSampleCB(trainer, test_dataset=hand_picked_ds, num_samples=8, max_new_tokens=256)\n",
    "trainer.add_callback(wandb_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4302997f-b5e6-4115-bd03-17b0658a78e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 5:22:22, Epoch 28/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.395000</td>\n",
       "      <td>1.446921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.017300</td>\n",
       "      <td>1.112553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.867100</td>\n",
       "      <td>0.965235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.899200</td>\n",
       "      <td>0.931866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.827400</td>\n",
       "      <td>0.925065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=1.1087499910593033, metrics={'train_runtime': 19379.6649, 'train_samples_per_second': 0.826, 'train_steps_per_second': 0.026, 'total_flos': 2.550104850432e+17, 'train_loss': 1.1087499910593033, 'epoch': 28.88})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25b5e1ba-b9c6-44d5-8bae-9f22b8c2ea84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output/yfk0igjz-meta-llama_Llama-2-7b-hf-ft)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact yfk0igjz-meta-llama_Llama-2-7b-hf-ft logged.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(trainer, output_dir):\n",
    "    \"Save the model to a folder inside {output_dir} prepending the run name\"\n",
    "    model_name = f\"{wandb.run.id}-{trainer.model.name_or_path}-ft\".replace(\"/\",\"_\")\n",
    "    model_folder = Path(output_dir) / model_name\n",
    "    model_folder.mkdir(parents=True, exist_ok=True)\n",
    "    trainer.save_model(model_folder)\n",
    "    return model_name, model_folder\n",
    "\n",
    "def create_model_artifact(model_name, model_folder):\n",
    "    \"Creates a Weights & Biases artifact for the saved model\"\n",
    "    at = wandb.Artifact(\n",
    "        name=model_name,\n",
    "        type=\"model\",\n",
    "        description=\"Finetuned model on Otto dataset\",\n",
    "        metadata={\"peft\": peft_config,\n",
    "                  \"quantization\": quantization_config,\n",
    "                  \"prompt_func\": mistral_prompt)\n",
    "                 },\n",
    "    )\n",
    "    at.add_dir(model_folder)\n",
    "    wandb.log_artifact(at)\n",
    "    print(f\"Artifact {model_name} logged.\")\n",
    "    \n",
    "def save_and_log(trainer, output_dir):    \n",
    "    model_name, model_folder = save_model(trainer, output_dir)\n",
    "    create_model_artifact(model_name, model_folder)\n",
    "\n",
    "save_and_log(trainer, script_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "167f123a-c353-46b6-b2ab-d1394c083e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/runtime</td><td>█▇▅▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▂▄██</td></tr><tr><td>eval/steps_per_second</td><td>▁▂▄▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.92507</td></tr><tr><td>eval/runtime</td><td>4.5587</td></tr><tr><td>eval/samples_per_second</td><td>13.6</td></tr><tr><td>eval/steps_per_second</td><td>6.8</td></tr><tr><td>train/epoch</td><td>28.88</td></tr><tr><td>train/global_step</td><td>500</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8274</td></tr><tr><td>train/total_flos</td><td>2.550104850432e+17</td></tr><tr><td>train/train_loss</td><td>1.10875</td></tr><tr><td>train/train_runtime</td><td>19379.6649</td></tr><tr><td>train/train_samples_per_second</td><td>0.826</td></tr><tr><td>train/train_steps_per_second</td><td>0.026</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magical-magic-82</strong> at: <a href='https://wandb.ai/capecape/otto/runs/yfk0igjz' target=\"_blank\">https://wandb.ai/capecape/otto/runs/yfk0igjz</a><br/> View job at <a href='https://wandb.ai/capecape/otto/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMTUyODE1Mw==/version_details/v0' target=\"_blank\">https://wandb.ai/capecape/otto/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMTUyODE1Mw==/version_details/v0</a><br/>Synced 6 W&B file(s), 5 media file(s), 16 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231031_001144-yfk0igjz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3f6b9-b2d8-46c1-8564-e17dc203d963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
